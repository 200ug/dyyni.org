---
title: "Websites should be w3m compatible"
date: "2026-01-30T21:48:45+02:00"
draft: false
post_number: "004"
---

W3m is a text-based web browser that you can use through a terminal emulator. In essence it renders a website's HTML entities via ASCII and Unicode, with neither JavaScript nor CSS. This allows the user to focus on the actual content of the said website without distractions caused by extravagant UI design or hindered performance due to bloated web frameworks.

In my honest opinion, every website where the text is the primary focus, say a news site for example, should be readable with w3m or a similar alternative. Don't get me wrong, the point isn't that somebody would actually daily drive a browser like this in the modern day, but rather the readability and parseability this kind of approach would bring. I suppose some companies utilize JavaScript and multi-stage content loading to prevent scraping, but that's hardly a hurdle for competent actors with the bare minimum of knowledge to stay ahead of the curve. Even LinkedIn is constantly being scraped, even though they're one of the more well-known examples of fiercely protecting their platform's content.

![Image of an easter egg on dyyni.org landing page](/images/posts/w3m-websites/egg.png)

